{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:\\\\Users\\\\avrahami\\\\Documents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:\\\\Users\\\\avrahami\\\\Documents\\\\Private\\\\IDC\\\\advacned_ml_course\\\\2020\\\\HW\\\\HW2\\\\kaggle_data\\\\noncomm_use_subset\\\\noncomm_use_subset\\\\pmc_json\"\n",
    "amout_of_files_to_use = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        cur_file_as_dict = json.load(f)\n",
    "    list_of_texts = cur_file_as_dict['body_text']\n",
    "    full_text = ' '.join([lof['text'] for lof in list_of_texts])\n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2212 files have been found, we will use the top 10 as set in the configuration\n"
     ]
    }
   ],
   "source": [
    "files_found = [f for f in os.listdir(data_path) if f.endswith('.xml.json')]\n",
    "files_found_full_path = [os.path.join(data_path, f) for f in files_found]\n",
    "files_path_subset = files_found_full_path[0:amout_of_files_to_use]\n",
    "print(f\"{len(files_found)} files have been found, we will use the top {amout_of_files_to_use} as set in the configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing between pairs of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_document_idx = 0\n",
    "second_document_idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the first document 22665\n",
      "Length of the second document 37354\n",
      "Length of the two text combined is 60019\n"
     ]
    }
   ],
   "source": [
    "first_file = files_path_subset[first_document_idx]\n",
    "first_text = extract_text(first_file)\n",
    "\n",
    "print(f\"Length of the first document {len(bytes(first_text, 'utf-8'))}\")\n",
    "\n",
    "second_file = files_path_subset[second_document_idx]\n",
    "second_text = extract_text(second_file)\n",
    "\n",
    "print(f\"Length of the second document {len(bytes(second_text, 'utf-8'))}\")\n",
    "\n",
    "texts_concat = first_text + second_text\n",
    "print(f\"Length of the two text combined is {len(bytes(texts_concat, 'utf-8'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the zipped first document 7219\n",
      "Length of the zipped second document 12340\n",
      "Length of the zipped first+second documents 18706\n"
     ]
    }
   ],
   "source": [
    "# now doing gzip operation on each option\n",
    "zipped_first_text = gzip.compress(bytes(first_text,'utf-8'))\n",
    "print(f\"Length of the zipped first document {len(zipped_first_text)}\")\n",
    "\n",
    "zipped_second_text = gzip.compress(bytes(second_text,'utf-8'))\n",
    "print(f\"Length of the zipped second document {len(zipped_second_text)}\")\n",
    "\n",
    "zipped_both_texts = gzip.compress(bytes(texts_concat,'utf-8'))\n",
    "print(f\"Length of the zipped first+second documents {len(zipped_both_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First document compression substraction result: 15446\n",
      "Second document compression substraction result: 25014\n",
      "Both documents substraction result (focusing on the first document): 11487\n",
      "Both documents substraction result (focusing on the second document): 6366\n"
     ]
    }
   ],
   "source": [
    "# calculating some substraction values between different combinations\n",
    "print(f\"First document compression substraction result: {len(bytes(first_text, 'utf-8')) - len(zipped_first_text)}\")\n",
    "print(f\"Second document compression substraction result: {len(bytes(second_text, 'utf-8')) - len(zipped_second_text)}\")\n",
    "\n",
    "print(f\"Both documents substraction result (focusing on the first document): {len(zipped_both_texts) - len(zipped_first_text)}\")\n",
    "print(f\"Both documents substraction result (focusing on the second document): {len(zipped_both_texts) - len(zipped_second_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if we want to focus on both documents and not a specific one (Jensen-Shannon alike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both documents substraction result: 853\n"
     ]
    }
   ],
   "source": [
    "both_texts = zipped_first_text + zipped_second_text\n",
    "print(f\"Both documents substraction result: {len(both_texts) - len(zipped_both_texts)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
